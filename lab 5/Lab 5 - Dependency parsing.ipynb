{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Dependency parsing\n",
    "Laboration 5 in EDAN20 @ LTH - http://cs.lth.se/edan20/coursework/assignment-5/\n",
    "\n",
    "Author: Jonatan Kronander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "The objectives of this assignment are to:\n",
    "* Know what a dependency graph is\n",
    "* Understand the principles of Nivre's parsing mechanisms\n",
    "* Extend Nivre's parser with a guiding predicate that parses an annotated dependency graph\n",
    "* Extract features to learn parsing actions from an annotated corpus\n",
    "* Write a short report on your results\n",
    "* In this assignment, you will only generate the machine-learning models from the extracted features. You will complete the parser and apply it in the next assignment.\n",
    "\n",
    "This assignment is inspired by the shared task of the Tenth conference on computational natural language learning,CONLL-X, and uses a subset of their data. The conference site contains a description of multilingual dependency parsing, reference papers, training and test sets for a variety of languages, as well as evaluation programs. See also CONLL 2007, on the same topic.\n",
    "\n",
    "Please note that the original CoNLL-X site is down. To access the pages, use the Archive.org site: https://web.archive.org/web/20161105025307/http://ilk.uvt.nl/conll/ and to download the data sets, use the local copies.\n",
    "\n",
    "In this session, you will implement a dependency parser for Swedish. Should you want to use another corpus, please tell me in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a training and a test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the CONLL-X Swedish corpus. Download the tar archives containing the training and test sets for Swedish and uncompress them: \n",
    "http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/swedish_talbanken05_train.conll http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/swedish_talbanken05_test_blind.conll http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/swedish_talbanken05_test.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "b_train_text = urlopen(\"http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/swedish_talbanken05_train.conll\").read() # Open file and read\n",
    "train_text = str(b_train_text,'utf-8')\n",
    "\n",
    "b_test_text = urlopen(\"http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/swedish_talbanken05_test.conll\").read() # Open file and read\n",
    "test_text = str(b_test_text,'utf-8')\n",
    "\n",
    "b_blind_test_text = urlopen(\"http://fileadmin.cs.lth.se/cs/Education/EDAN20/corpus/conllx/sv/swedish_talbanken05_test_blind.conll\").read() # Open file and read\n",
    "blind_test_text = str(b_blind_test_text,'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = open('train.conll', 'w')\n",
    "\n",
    "for sentence in train_text:   \n",
    "    f_out.write(sentence)\n",
    "f_out.close()\n",
    "\n",
    "f_out = open('test.conll', 'w')\n",
    "\n",
    "for sentence in test_text:   \n",
    "    f_out.write(sentence)\n",
    "f_out.close()\n",
    "\n",
    "f_out = open('test_blind.conll', 'w')\n",
    "\n",
    "for sentence in blind_test_text:   \n",
    "    f_out.write(sentence)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nivre's parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence with a projective dependency graph, there is an action sequence that enables Nivre's parser to generate this graph. Gold standard parsing corresponds to the sequence of parsing actions, left-arc (la), right-arc (ra), shift (sh), and reduce (re) that produces the manually-obtained, gold standard, graph.\n",
    "\n",
    "Using an annotated corpus, we can derive all the action sequences producing the manually-parsed sentences (provided that they are projective). We can then train a classifier to predict an action from a current parsing context. To be able to predict the next action from a given parsing state, gold standard parsing must also extract feature vectors at each step of the parsing procedure. The simplest parsing context corresponds to words' part of speech on the top of the stack and head of the input list (the queue).\n",
    "\n",
    "Once the data collected, the training procedure will produce a 4-class classifier that you will embed in Nivre's parser to choose the next action. During parsing, Nivre's parser will call the classifier to choose the next action in the set {la, ra, sh, re} using the current context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Run the dparser.py program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transition\n",
    "import conll\n",
    "import dparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_2006 = ['id', 'form', 'lemma', 'cpostag', 'postag', 'feats', 'head', 'deprel', 'phead', 'pdeprel']\n",
    "\n",
    "sentences = conll.read_sentences(\"train.conll\")\n",
    "    \n",
    "formatted_corpus = conll.split_rows(sentences, column_names_2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code from dparser main()\n",
    "\"\"\"\n",
    "sent_cnt = 0\n",
    "for sentence in formatted_corpus:\n",
    "    sent_cnt += 1\n",
    "    #if sent_cnt % 1000 == 0:\n",
    "        #print(sent_cnt, 'sentences on', len(formatted_corpus), flush=True)\n",
    "    stack = []\n",
    "    queue = list(sentence)\n",
    "    graph = {}\n",
    "    graph['heads'] = {}\n",
    "    graph['heads']['0'] = '0'\n",
    "    graph['deprels'] = {}\n",
    "    graph['deprels']['0'] = 'ROOT'\n",
    "    transitions = []\n",
    "    while queue:\n",
    "        stack, queue, graph, trans = dparser.reference(stack, queue, graph)\n",
    "        transitions.append(trans)\n",
    "    stack, graph = transition.empty_stack(stack, graph)\n",
    "    #print('Equal graphs:', transition.equal_graphs(sentence, graph))\n",
    "\n",
    "    # Poorman's projectivization to have well-formed graphs.\n",
    "    for word in sentence:\n",
    "        word['head'] = graph['heads'][word['id']]\n",
    "    #print(transitions)\n",
    "    #print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sh', 'sh', 'la.DT', 'sh', 'la.SS', 'ra.ROOT', 'sh', 'la.IM', 'ra.VG', 'sh', 'la.DT', 'ra.OO', 'sh', 'sh', 'la.SS', 'la.++', 're', 're', 'ra.MS', 'ra.VG', 'ra.OA', 'sh', 'la.IM', 'ra.PA', 'ra.OO', 're', 'ra.VO', 'ra.PL', 're', 'ra.AA', 'ra.PA', 'sh', 'la.IK', 'ra.CC', 'sh', 'la.++', 'ra.CC', 're', 're', 're', 're', 'ra.AA', 'ra.HD', 're', 'ra.HD', 'sh', 'sh', 'la.UK', 'sh', 'la.KA', 'la.IM', 'ra.PA', 'ra.AA', 'sh', 'la.DT', 'ra.PA', 're', 're', 'ra.AA', 'sh', 'sh', 'la.SS', 'la.UK', 'ra.PA', 'ra.IO', 'sh', 'sh', 'la.AT', 'la.DT', 're', 'ra.OO', 'sh', 'la.UK', 'ra.AN', 'sh', 'la.++', 'ra.CC', 'ra.ET', 'ra.PA', 'ra.HD', 're', 're', 're', 're', 're', 're', 're', 're', 're', 're', 're', 're', 're', 're', 're', 're', 'ra.IP']\n"
     ]
    }
   ],
   "source": [
    "print(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tJag\t_\tPO\tPO\t_\t2\tSS\t_\t_\n",
      "2\ttycker\t_\tVV\tVV\t_\t0\tROOT\t_\t_\n",
      "3\tdet\t_\tPO\tPO\t_\t2\tOO\t_\t_\n",
      "4\tinte\t_\tAB\tAB\t_\t2\tNA\t_\t_\n",
      "5\t.\t_\tIP\tIP\t_\t2\tIP\t_\t_\n"
     ]
    }
   ],
   "source": [
    "print(sentences[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Understand from the slides and the program how Nivre's parser is extended to carry out a gold standard parsing. Given a manually-annotated dependency graph, what are the conditions on the stack and the current input list -- the queue -- to execute left-arc, right-arc, shift, or reduce? Start with left-arc and right-arc, which are the simplest ones. https://github.com/pnugues/ilppp/blob/master/slides/EDAN20_ch13.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. The parser can only deal with projective sentences. In the case of a nonprojective one, the parsed graph and the manually-annotated sentence are not equal. Examine one such sentence and explain why it is not projective. Take a short one (the shortest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of nonprojective: \"<root> John saw a dog yesterday which was a Yorkshire Terrier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
