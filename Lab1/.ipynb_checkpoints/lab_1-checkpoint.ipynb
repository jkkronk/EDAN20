{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laboration 1 in EDAN20 @ LTH - http://cs.lth.se/edan20/coursework/assignment-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The objectives of this assignment are to:\n",
    "\n",
    "-Write a program that collects all the words from a set of documents\n",
    "\n",
    "-Build an index from the words\n",
    "\n",
    "-Know what indexing is\n",
    "\n",
    "-Represent a document using the Tf.Idf value\n",
    "\n",
    "-Write a short report of 1 to 2 pages on the assignment\n",
    "\n",
    "-Read a short text on an industrial system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing one file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The index file will contain all the unique words in the document, where each word is associated with the list of its positions in the document.\n",
    "\n",
    "* You will represent this index as a dictionary where the keys will be the words and the values, the lists of positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As words, you will consider all the strings of letters that you will set in lower case. You will not index the rest (i.e. numbers or symbols).\n",
    "\n",
    "This is done by first using function txtClean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def txtClean(text):\n",
    "    \"\"\"\n",
    "    Replace capital characters to small characters\n",
    "    \n",
    "    Input txt file\n",
    "    Output txt file\n",
    "    \"\"\"\n",
    "    # Remove new lines\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    \n",
    "    # Replace [A-Ö] with [a-ö]\n",
    "    def toLowercase(matchobj):\n",
    "        return matchobj.group(1).lower()\n",
    "    \n",
    "    text = re.sub(r'([A-Z])', toLowercase, text)\n",
    "    \n",
    "    # Remove number and symbols\n",
    "    #text = re.sub('[^a-zåäö ]', ' ', text)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"Selma/bannlyst.txt\").read()  \n",
    "txt = txtClean(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To extract the words, you will use Unicode regular expressions. Do not use \\w+, for instance, but the Unicode equivalent. The word positions will correspond to the number of characters from the beginning of the file. (The word offset from the beginning)\n",
    "\n",
    "* You will use finditer() to find the positions of the words. This will return you match objects, where you will get the matches and the positions with the group() and start() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2dict(text,originaltext):\n",
    "    \"\"\"\n",
    "    Creates a dict with (word:list[index apperences]) from input string\n",
    "    \n",
    "    Input string, string\n",
    "    Output dict\n",
    "    \"\"\"\n",
    "    stringList = re.findall(r\"[a-zåäö]+\",text) #This finds all words from a txt file. r\"[a-zåäö]+ equal to r\"\\w+\" \n",
    "\n",
    "    stringDict = dict.fromkeys(stringList) #Creates dict (and remove doublicates)\n",
    "\n",
    "    for word in stringDict:\n",
    "        wordIndices = []\n",
    "        pattern = r\"\\b\"+word+ r\"\\b\" #Only look at word \n",
    "        \n",
    "        for m in re.finditer(pattern, originaltext): #Iterate thorugh every word\n",
    "            wordIndices.append(m.start(0))\n",
    "            \n",
    "        stringDict.update({word:wordIndices})\n",
    "    return stringDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtDict = string2dict(txt,text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with bannlyst text. The word gjord occurs three times in the text at positions 8551, 183692, and 220875, uppklarnande, once at position 8567, and stjärnor, once at position 8590. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8551, 183692, 220875]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtDict['gjord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8567]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtDict['uppklarnande']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8590]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtDict['stjärnor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You will use the pickle package to write your dictionary in an file, see https://wiki.python.org/moin/UsingPickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
